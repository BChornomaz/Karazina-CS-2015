## Задания по распределленным системам
Четыре или пять лабораторок с сроками сдачи (баллы будут чуть позже):
- 1,  до 27 Марта, Apache Spark, подсчёт треугольников;
- 2,  до 13 Апреля, Apache Spark, инвертированный индекс;
- 3,  до 3 Мая, Spark SQL + Streaming;
- 4,  до конца, Go;

Сдача после срока иногда возможна но не приветствуется (со штрафом или вообще нет). Оптимальная форма сдачи задания - прислать по почте (просьба  тексте письма указывать чья работа). Лабораторную можно делать вдвоем, при этом в письме следует указать обоих авторов. Если у меня будут возникать вопросы по работе, я могу попросить автора(авторов) встретиться для сдачи лично.

Если сданные работы будут черезмерно похожи, это будет считаться читерством и засчитываться такие работы не будут. Заметьте, что такого результата можно достигнуть не только переписывая друг у друга, но и независимо переписывая из одних и тех же открытых источников.

### Лаба 1 - Apache Spark, подсчет треугольников, до 27 марта, 10 баллов

По данному файлу содержащему список ребер (неориентированного) графа написать Spark-приложение, считающее в этом графе количество треугольников.

Файл состоит из строк, каждая содержит два числа - вершины соответствующего ребра. Файл `graph.txt` прилагается.

Для этого вам надо, например, создать RDD из файла, потом преобраззовать его в список пар при помощи map, затем несколькими операциями join выделить в нем треугольники и возвратить результат при помощи действия count. Для ускорения работы промежуточное RDD со списком ребер можно закешировать операцией cashe.

Скачать Spark можно [здесь](http://spark.apache.org/downloads.html), рекомендуется скачивать собранную версию со встроенным хадупом, т.к. ее можно с ходу запускать. Инструкции по написанию и запуску приложений на Spark [здесь](http://spark.apache.org/docs/latest/programming-guide.html). С моей точки зрения, легче всего реализовывать на питоне т.к. можно не компилировать, а просто отправлять .py файл на выполнение. Для java надо сначало скомпилировать в jar, а потом уже запускать jar. Файл с графом Spark может брать прямо из (запущенного) Hadoop-кластера, для это файл надо указывать по его сетевому имени в Hadoop, например так

```
val file = sc.textFile("hdfs://localhost:9000/mr_test/input/anonymous-msweb.data").
```

### Лаба 2 - Apache Spark, инвертирование индекса, до 13 апреля, 12 баллов
Построить [инвертированный индекс](https://ru.wikipedia.org/wiki/Инвертированный_индекс) для датасета представляющего собой набор сообщений. Данные представляют собой файлы с текстом сообщений разложенные по каталогам. Имя файла - это индекс записи.  

В результате должен получиться файл `index.csv` содержащий три поля для каждого слова: слово, общее количество вхождений этого слова (по всем документам), список документов через пробел. Например:

```
  accept,258,54243 60890 60884 76067 105252
  crud, 4, 104959 16152
```
(результат приведен только для примера)

При считывании файлов следует:
  - исключить строки со служебной информацией: `Path:`, `Newsgroups:`, `xxx writes:`, ...;
  - запятые, точки, пробелы, etc. считать разделителями;
  - брать только слова, состоящие из латинсих букв и символа `'`;
  - все слова привести к нижнему регистру;
  - вообще, ориентирутесь на здравый смысл, посмотрите глазами на список слов, который получается, чтоб в него не попал мусор, н с другой стороны чтоб он отражал структуру текста, за исключением, возможно, небольшого количества плохих случаев;


Данные взяты [отсюда] (http://www.cs.cmu.edu/afs/cs/project/theo-20/www/data/news20.html)

### Лаба 3 - Twitter, Streaming & Spark SQL , до 4 мая, 16 баллов

Написать скрипт, который с каждые 20 секунд будет считать общее количество твитов сделанных в последние две минуты, содержащие определенный хэш-тег (какой - выберите сами), а также топ-10 слов (и их количество), которые попадаются в этих твитах. Сделайте, пожалуйста, основную обработку данных прри помощи SparkSQL - это просто, по сути вы пишете обычный SQL-запрос. В Rdd вам надо оставить только первичную обработку входного потока, вроде разбивания на слова. Временные рамки 2 минуты с 20 сек. обновлением нужны скорее для удобства тестирования. Для более содержательных результатов интервал можно увеличить.

В совокупности, вам надо будет применить [Spark SQL](http://spark.apache.org/docs/latest/sql-programming-guide.html) - достаточно формально, и [Spark Streaming](http://spark.apache.org/docs/latest/streaming-programming-guide.html) - чуть подробнее.

Для того, чтоб подключиться к твиттеру, для начала надо завести там аккаунт и получить [Twitter API Credentials](https://databricks-training.s3.amazonaws.com/realtime-processing-with-spark-streaming.html#twitter-credential-setup).

В Java и Scala стриминг из твиттера включен в Spark, [org.apache.spark.streaming.twitter](https://spark.apache.org/docs/1.6.2/streaming-programming-guide.html#advanced-sources) (правда эта библиотека вроде как не включена в стандартный пакет, ее надо доставлять отдельно, через Maven - у меня не получилось).

В питоне родная интеграция твиттера в SparkStreaming не реализована, но можно сделать или [при поомощи socketTextStream](http://www.awesomestats.in/spark-twitter-stream/)(обратите внимание, что тут запускаются два процесса), или при помощи [Kafka](https://www.rittmanmead.com/blog/2017/01/getting-started-with-spark-streaming-with-python-and-kafka/).

### Лаба 4 - Go channels, 22 балла

Эта лабораторная будет по языку [go](https://golang.org), он простой и легко ставится. Нам он интересен потому что естственным образом поддерживает параллелизм основанный на обмене сообщениями, реализованый при помощи т.н. [goroutines](https://gobyexample.com/goroutines) и каналов: [channels](https://gobyexample.com/channels). Есть гайд по синтаксису [тут](https://tour.golang.org/welcome/1) - но в целом синтаксис простой и каких-то тонкостей оттуда нам не надо.

Вам надо будет реализовать систему которая  У вас есть некоторое количество процессов которые ставят задания (clients), некоторое количество процессов которые решают задачи (workers) и управляющий процесс, который в зависимости от количества и активности клиентов порождает или убивает обработчиков. Нам не очень важно какие задачи будут непосредственно решать разработчики, но для примера давайте определимся что клиент называет имя случайного файла из тех, которые были в третьей лабораторке, а обработчик считает и возвращает клиенту количество слов в данном файле.

Характеристики системы такие:
- система стартует с десятью клиентами и двумя обработчиками;
- клиент генерирует задачи с некоторой фиксированной частотой, которая может меняться (глобально), и которая в начале равна 50 ms, после этого он некоторое время (100 ms) ждет ответа. Если ответ не поступает, то он отменяет задачу;
- обработчик решает задачи по мере поступления (из некоторого общего пула). Для того, чтоб лучше видеть динамику, я попрошу также ввести некоторую задержку после выполнения задачи, скажем, 20 ms - это нужно для того, чтоб увеличение количества обработчиков повышало производительность нашей системы, независимо от реального количества процессоров и распределения задач между ними;
- управляющий процесс регулирует количество обработчиков. Если количество отказов за последние 1000 ms превысило 20% от общего количества, то он создает нового обработчика. Если на протяжениии последних 1000 ms одновременно работало не болеее 50% от общего количества обработчиков, то он убивает одного из них;
- каждые 5 s система выводит в консоль количество работающих клиентов, обработчиков, уровень активности клиентов, а также количество сгенерированных за последние 5 s задач клиентами, а также количество решенных задач и отказов (абсолютно и в процентах).
- количество и активность клиентов (но не обработчиков) может регулироваться пользователем динамически: `+` добавляет клиента, `-` убирает, `<` уменьшает активность клиентов на 10%, `>` увеличивает (также просьба по нажатию этих клавиш дделать подтверждающие записи в консоль, что то вроде `+1 клиент (теперь 11)`). `Esc` завершает выполнение;
- большая просьба, вынести значения фигурирующие в описании (начальное число клиентов и обработчиков, параметры определяющие активность, пороговые значения для управляющего процесса, ...) в константы в начале программмы;
- просьба использовать только базоовые примитивы для синхронизации `go`, `chan`, `select`, также для регулярных событий моогут быть полезны каналы из модуля [time](https://mmcgrana.github.io/2012/09/go-by-example-timers-and-tickers.html). Этих средств должно быть достаточно. 






